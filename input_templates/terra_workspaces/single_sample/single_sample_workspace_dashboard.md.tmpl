## GATK-SV Best Practices for Structural Variation Discovery on Single Samples

An integrated structural variation detection and resolution pipeline designed to call
many forms of structural variation in whole genome sequencing data obtained from a single sample. The pipeline will identify,
genotype, and annotate structural variation from the following variant types: 

- Copy number variants, including deletions and duplications
- Insertions 
- Inversions 
- Reciprocal chromosomal translocations
- Additional forms of complex structural variation 

**Pipeline Background**

The Single Sample pipeline is based upon the GATK-SV cohort pipeline, which jointly analyzes WGS data from large research
cohorts and has been used to create SV call sets for [gnomAD-SV](https://www.nature.com/articles/s41586-020-2287-8) and the
[SFARI SSC autism research study](http://dx.doi.org/10.1038/s41588-018-0107-y). 

**Extending SV detection to small datasets**
The Single Sample pipeline in this workspace
is designed to facilitate running the methods developed for the cohort-more GATK-SV pipeline on small data sets or in 
clinical contexts where batching large numbers of samples is not an option. To do so, it uses precomputed data, SV calls,
and model parameters computed by the cohort pipeline on a reference panel composed of similar samples. The pipeline integrates this
precomputed information with signals extracted from the input CRAM file to produce a call set similar in quality to results
computed by the cohort pipeline in a computationally tractable and reproducible manner.

GATK-SV uses [Manta](https://github.com/Illumina/manta), [WHAM](https://github.com/zeeev/wham), GATK gCNV, and [cn.MOPS](https://pubmed.ncbi.nlm.nih.gov/22302147/) 
as raw calling algorithms, and then integrates, filters, refines, and annotates 
the calls from these tools to produce a final output. Please note that most large published joint call sets produced by
GATK-SV, including gnomAD-SV, included the tool MELT, a state-of-the-art mobile element insertion (MEI) detector, as part of the pipeline. 
Due to licensing restrictions, we cannot provide a public docker image or reference panel VCFs for this algorithm. The 
version of the pipeline configured in this workspace does not run MELT or include MELT calls for the reference panel. Therefore, 
the output will be less sensitive to MEI calls that might appear in gnomAD or other joint call sets. 

Source code for all GATK-SV pipelines is stored and documented in the [GATK-SV GitHub repository](https://github.com/broadinstitute/gatk-sv).

Please cite the [gnomAD-SV](https://www.nature.com/articles/s41586-020-2287-8) paper when referring to these methods.

## Data

### Case Sample

This workspace includes a NA12878 input WGS CRAM file configured in the workspace samples data table. This file is part of the
high coverage (30X) [WGS data](https://www.internationalgenome.org/data-portal/data-collection/30x-grch38) for the 1000
Genomes Project samples generated by the New York Genome Center and hosted in
[AnVIL](https://app.terra.bio/#workspaces/anvil-datastorage/1000G-high-coverage-2019). 

### Reference Panel

The reference panel configured in this workspace consists of data and calls computed from 156 publicly available samples
chosen from the NYGC/AnVIL 1000 Genomes high coverage data linked above. 

Inputs to the pipeline for the reference panel include:
- A precomputed SV callset VCF, and joint-called depth-based CNV call files 
- Raw calls for the reference panel samples from Manta and WHAM 
- Trained models for calling copy number variation in GATK gCNV case mode
- Parameters learned by the cohort mode pipeline in training machine learning models on the reference panel samples.

These resources are primarily configured in the "Workspace Data" for this workspace. However, several of the resources need 
to be passed  to the workflow as large lists of files or strings. Due to Terra limitations on uploading data containing lists to the
workspace data table, these resources are specified directly in the workflow configuration.

### Reference Resources

The pipeline uses a number of resource and data files computed for the hg38 reference:
- Reference sequences and indices 
- Genome annotation tracks such as segmental duplication and RepeatMasker tracks
- Data used for annotation of called variants, including GenCode gene annotations and gnomAD site allele frequencies. 

## GATKSVSingleSample Workflow

### What does it do?

The workflow calls structural variations on a single input CRAM by running the GATK-SV Single Sample Pipeline end-to-end.

#### What does it require as input?

The workflow accepts a single CRAM or BAM file as input, configured in the following parameters:

|Input Type|Input Name|Description|
|---------|--------|--------------|
|`String`|`sample_id`|Case sample identifier|
|`File`|`bam_or_cram_file`|Path to the GCS location of the input CRAM or BAM file|
|`String`|`batch`|Arbitrary name to be assigned to the run|
|`Boolean`|`requester_pays_cram`|Set to `true` if the case data is stored in a requester-pays GCS bucket|

#### Additional workspace-level inputs

- Reference resources for hg38 
- Input data for the reference panel
- The set of docker images used in the pipeline. 
  
Please contact GATK-SV developers if you are interested in customizing these
inputs beyond their defaults.

#### What does it return as output?

|Output Type|Output Name|Description|
|---------|--------|--------------|
|`File`|`final_vcf`|SV VCF output for the pipeline. Includes all sites genotyped as variant in the case sample and genotypes for the reference panel. Sites are annotated with overlap of functional genome elements and allele frequencies of matching variants in gnomAD|
|`File`|`final_vcf_idx`|Index file for `final_vcf`|
|`File`|`final_bed`|Final output in BED format. Filter status, list of variant samples, and all VCF INFO fields are reported as additional columns.|
|`File`|`metrics_file`|Metrics computed from the input data and intermediate and final VCFs. Includes metrics on the SV evidence, and on the number of variants called, broken down by type and size range.|
|`File`|`qc_file`|Quality-control check file. This extracts several key metrics from the `metrics_file` and compares them to pre-specified threshold values. If any QC checks evaluate to FAIL, further diagnostics may be required.|
|`File`|`ploidy_matrix`|Matrix of contig ploidy estimates computed by GATK gCNV.|
|`File`|`ploidy_plots`|Plots of contig ploidy generated from `ploidy_matrix`|
|`File`|`non_genotyped_unique_depth_calls`|This VCF file contains any depth based calls made in the case sample that did not pass genotyping checks and do not match a depth-based call from the reference panel. If very high sensitivity is desired, examine this file for additional large CNV calls.|
|`File`|`non_genotyped_unique_depth_calls_idx`|Index file for `non_genotyped_unique_depth_calls`|
|`File`|`pre_cleanup_vcf`|VCF output in a representation used internally in the pipeline. This file is less compliant with the VCF spec and is intended for debugging purposes.|
|`File`|`pre_cleanup_vcf_idx`|Index file for `pre_cleanup_vcf`|

#### Example time and cost run on sample data

|Sample Name|Sample Size|Time|Cost $|
|-----------|-----------|----|------|
|NA12878|18.17 GiB|23hrs|~$7.34|

#### To use this workflow on your own data

If you would like to run this workflow on your own samples (which must be medium-to-high coverage WGS data):

- Clone this workspace into a Terra project you have access to
- In the cloned workspace, upload rows to the Sample and (optionally) the Participant Data Table that describe your samples.
  Ensure that the rows you add to the Sample table contain the columns `sample_id`, `bam_or_cram_file`, and `requester_pays_cram`,
  populated appropriately.
- There is no need to modify values in the workspace data or method configuration. If you are interested in modifying the reference
  genome resources or reference panel, please contact the GATK team for support as listed below.
- Launch the workflow from the "Workflows" tab, selecting your samples as the inputs.

Please check the `qc_file` output for each sample at the end of the run to screen for data quality issues.

#### Contact information
For questions about this workspace please visit the Featured Workspaces topic on the Terra forum. Use the search box to see if other users have asked the same question previously. If not, post and tag @Chris Whelan or @Mark Walker so that we get notified.

This material is provided by the GATK Team. Please post any questions or concerns regarding the GATK tool to the GATK forum.

##### License 

Copyright (c) 2009-2020, Broad Institute, Inc. All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.

* Neither the name Broad Institute, Inc. nor the names of its
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.



