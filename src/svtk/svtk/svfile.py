# -*- coding: utf-8 -*-
#
"""
svfile.py

Wrap the pysam API to permit clustering of standardized SV VCF records.
"""

import numpy as np
from collections import defaultdict
from .utils import recip, make_bnd_alt, update_best_genotypes, get_called_samples
from .genomeslink import GSNode


class SVFile(object):
    def __init__(self, vcf):
        """
        Wrapper for standardized VCF files.

        Parameters
        ----------
        vcf : pysam.VariantFile
        """
        self.reader = vcf
        self.filename = vcf.filename.decode('utf-8')
        self.samples = list(self.reader.header.samples)

        # Confirm all standard INFO fields are present
        required_info = 'SVTYPE CHR2 END STRANDS SVLEN ALGORITHMS'.split()
        for info in required_info:
            if info not in self.reader.header.info.keys():
                msg = "Required INFO field {0} not found in file {1}"
                msg = msg.format(info, self.filename)
                raise KeyError(msg)

        # Unfortunately no way to index into "source" metadata record
        # via pysam API, must manually check all header records
        self.sources = None
        for hrec in self.reader.header.records:
            if hrec.key == 'source':
                self.sources = hrec.value.split(',')

        if self.sources is None:
            msg = "Source not specified in header of {0}"
            msg = msg.format(self.filename)
            raise KeyError(msg)

    def fetch(self, chrom, start=None, end=None):
        """
        Fetch only calls from specified region of SVFile.

        Requires Tabix index. Updates SVFile in place.

        Parameters
        ----------
        chrom : str
        start : int, optional
        end : int, optional
            Required if start specified
        """
        if start is not None and end is None:
            msg = 'Start {}:{} specified but no end coordinate provided'
            msg = msg.format(chrom, start)
            raise ValueError(msg)

        # First check if VCF is empty
        try:
            pos = self.reader.tell()
            next(self.reader)
            self.reader.seek(pos)
        except StopIteration:
            self.reader = iter(())
            return

        # Then check if index is present
        try:
            self.reader = self.reader.fetch(chrom, start, end)
        except ValueError:
            msg = 'No index found for {0}'.format(self.filename)
            raise FileNotFoundError(msg)

    def __iter__(self):
        return self

    def __next__(self):
        return self.next()

    def next(self):
        record = next(self.reader)
        return SVRecord(record)


class SVRecord(GSNode):
    """
    Clusterable VCF record.
    """

    def __init__(self, record):
        """
        record : pysam.VariantRecord
            Must specify 'CHR2' and 'END' in INFO
        """

        self.record = record
        self.sources = record.info['ALGORITHMS']
        self.called_samples = None

        chrA = record.chrom
        posA = record.pos
        chrB = record.info['CHR2']
        posB = record.stop
        name = record.id

        super().__init__(chrA, posA, chrB, posB, name)

    def get_called_samples_set(self):
        if self.called_samples is not None:
            return self.called_samples
        self.called_samples = set(get_called_samples(self.record))
        return self.called_samples

    def overlaps(self, other, frac=0.0):
        """
        Check if two records meet minimum reciprocal overlap.

        1) DEL, DUP, INV - reciprocal overlap calculated between SV intervals
        2) INS - intervals are calculated as insertion site plus SVLEN
        3) BND - always true
        """

        if self.is_tloc:
            return True
        if self.svtype == 'INS':
            # If either record's insertion length is unknown, consider
            # overlap met
            svlens = self.record.info['SVLEN'], other.record.info['SVLEN']
            if svlens[0] == -1 or svlens[1] == -1:
                return True
            # Otherwise, model insertion region as (coord + ins length)
            else:
                posBs = (self.posA + svlens[0], other.posA + svlens[1])
        else:
            posBs = (self.posB, other.posB)

        return recip(self.posA, posBs[0], other.posA, posBs[1], frac)

    @property
    def svtype(self):
        """
        Returns
        -------
        svtype : str
            One of {DEL, DUP, INV, BND}
        """
        return self.record.info['SVTYPE']

    @property
    def is_tloc(self):
        return self.chrA != self.chrB

    def __hash__(self):
        return id(self)


class SVRecordCluster:
    def __init__(self, records):
        self.records = records

    def sources(self):
        """
        Return list of source algorithms in clustered records.

        By default, searches for an ALGORITHMS INFO field

        Returns
        -------
        sources : list of str
        """
        call_sources = set()
        for record in self.records:
            sources = record.record.info.get('ALGORITHMS')
            if sources:
                call_sources = call_sources.union(sources)

        return sorted(call_sources)

    def merge_record_data(self, new_record):
        """
        Aggregate metadata (coordinates, alts, and INFO) of clustered records.

        * Original record IDs are preserved in a new INFO field
        * svtype is reported for base record

        Parameters
        ----------
        new_record : pysam.VariantRecord
            Blank record to fill with aggregated data

        Returns
        -------
        new_record : pysam.VariantRecord
            VCF record populated with aggregate cluster data
        """

        # Secondary records have duplicate POS/END/INFO
        # TODO: move secondary filtering elsewhere

        if len(self.records) == 0:
            return None

        base_record = self.records[0]

        new_record.chrom = base_record.chrA
        new_record.ref = base_record.record.ref
        new_record.info['SVTYPE'] = base_record.svtype
        new_record.info['CHR2'] = base_record.chrB

        # TODO: Check if strands should be merged
        new_record.info['STRANDS'] = base_record.record.info['STRANDS']

        # Merge coordinates
        POS, END, CIPOS, CIEND = self.merge_pos()
        new_record.pos = POS
        new_record.stop = END
        #  new_record.info['CIPOS'] = CIPOS
        #  new_record.info['CIEND'] = CIEND

        # Assign alts, updating translocation alt based on merged coordinates
        if new_record.info['SVTYPE'] == 'BND':
            strands = new_record.info['STRANDS']
            alt = make_bnd_alt(base_record.chrB, END, strands)
            new_record.alts = (alt, )
            new_record.stop = END
        if new_record.info['SVTYPE'] == 'INS':
            alts = set()
            for record in self.records:
                alts = alts.union(record.record.alts)
            if len(alts) > 1:
                alts = tuple(a for a in alts if a != '<INS>')
            new_record.alts = alts
            new_record.stop = END
        else:
            new_record.alts = base_record.record.alts
            new_record.stop = END

        # SVLEN for intra-chromosomal is -1
        if base_record.is_tloc:
            new_record.info['SVLEN'] = -1
        # SVLEN for insertions is median of observed insertions
        elif base_record.record.info['SVTYPE'] == 'INS':
            svlens = [r.record.info['SVLEN'] for r in self.records]
            svlens = [svlen for svlen in svlens if svlen > -1]
            if len(svlens) == 0:
                svlen = -1
            else:
                svlen = int(np.around(np.median(svlens)))
            new_record.info['SVLEN'] = svlen
        else:
            new_record.info['SVLEN'] = END - POS

        # QUAL, FILTER currently unused
        new_record.filter.add('PASS')

        # Report cluster RMSSTD
        #  new_record.info['RMSSTD'] = self.rmsstd

        # List of aggregate sources
        new_record.info['ALGORITHMS'] = self.sources()

        # If merging, all will have same CLUSTER ID
        if 'CLUSTER' in base_record.record.info:
            new_record.info['CLUSTER'] = base_record.record.info['CLUSTER']

        return new_record

    def merge_record_infos(self, new_record, header):
        """
        Aggregate INFO fields in child records
        """
        PROTECTED_INFOS = ('SVTYPE CHR2 END STRANDS SVLEN ALGORITHMS CIPOS '
                           'CIEND RMSSTD MEMBERS').split()
        records = [r.record for r in self.records]
        infos = defaultdict(list)

        for record in records:
            for info, value in record.info.items():
                if info not in PROTECTED_INFOS:
                    infos[info].append(value)

        for info, values in infos.items():
            if header.info[info].type == 'Flag':
                new_record.info[info] = True
            elif header.info[info].type == 'String':
                if header.info[info].number == '.':
                    new_record.info[info] = sorted(
                        set([v for vlist in values for v in vlist]))
                elif header.info[info].number == 1:
                    new_record.info[info] = ','.join(
                        sorted(set([v for vlist in values for v in vlist])))
                else:
                    new_record.info[info] = [
                        ','.join(vlist) for vlist in zip(values)]

            # TODO merge numeric INFO
            elif info == 'varGQ':
                new_record.info[info] = max(values)
            else:
                pass

        return new_record

    def merge_record_formats(self, new_record, sourcelist,
                             preserve_genotypes=False):
        """
        Aggregate sample genotype data across records.

        1) Set GT to 0/1 for samples called in any record, 0/0 otherwise.
        2) For each provided source, set a corresponding FORMAT field to 1
           for samples called by the source. If the FORMAT field is available
           in the record being merged, use per-sample data. If the FORMAT field
           is not available, use the record's ALGORITHMS to determine
           support for all samples called in that record.

        Parameters
        ----------
        new_record : pysam.VariantRecord
            Record to populate with FORMAT data
        sourcelist : list of str
            List of all sources to add a FORMAT field for

        Returns
        -------
        new_record : pysam.VariantRecord
            Populated record
        """

        # Seed with null values
        for sample in new_record.samples:
            new_record.samples[sample]['GT'] = (0, 0)

            #  for source in sourcelist:
            #  new_record.samples[sample][source] = 0

        # Update with called samples
        if preserve_genotypes:
            for fmt in new_record.format.keys():
                if fmt != 'GT':
                    del new_record.format[fmt]

            # then overwrite genotypes of non-multiallelic sites as necessary
            records = [r.record for r in self.records]
            update_best_genotypes(new_record, records,
                                  preserve_multiallelic=True)

        # TODO: optionally permit ./. instead of rejecting
        # I think that was an issue with one caller, maybe handle in preproc
        else:
            null_GTs = [(0, 0), (None, None), (0, ), (None, )]
            for record in self.records:
                for sample in record.record.samples:
                    gt = record.record.samples[sample]['GT']

                    # Skip samples without a call
                    if gt in null_GTs:
                        continue

                    # Otherwise call the sample in the new record
                    new_record.samples[sample]['GT'] = (0, 1)

        return new_record

    def merge_pos(self):
        """
        Compute aggregate POS/END of clustered SVRecords.

        Defaults to computing median of POS and END over constituent
        records. CIPOS/CIEND are calculated as (MIN - MEDIAN, MAX - MEDIAN)
        over POS and END.

        Returns
        -------
        POS : int
        END : int
        CIPOS : list of int
        CIEND : list of int
        """

        # Position bounds
        MIN_POS = min(rec.posA for rec in self.records)
        MAX_POS = max(rec.posA for rec in self.records)
        MIN_END = min(rec.posB for rec in self.records)
        MAX_END = max(rec.posB for rec in self.records)

        POS = int(np.median([rec.posA for rec in self.records]))
        END = int(np.median([rec.posB for rec in self.records]))
        CIPOS = [MIN_POS - POS, MAX_POS - POS]
        CIEND = [MIN_END - END, MAX_END - END]

        return POS, END, CIPOS, CIEND

    @property
    def rmsstd(self):
        """
        Root-mean-square standard deviation of cluster coordinates
        """

        if hasattr(self, '_rmsstd'):
            return self._rmmstd

        starts = np.array([record.posA for record in self.records])
        ends = np.array([record.posB for record in self.records])

        def _meanSS(X):
            mu = np.mean(X)
            return np.sum((X - mu) ** 2) / len(X)

        SS = _meanSS(starts) + _meanSS(ends)
        self._rmmstd = np.sqrt(SS)

        return self._rmmstd
